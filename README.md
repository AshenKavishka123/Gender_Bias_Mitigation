# Gender Bias Mitigation in GPT-2 Models

This repository contains the implementation and demonstration of a research project focused on **detecting and mitigating gender bias** in GPT-2 language models. The project was conducted as part of an academic module titled:

ğŸ“˜ **Module 3: Detecting and Mitigating Gender Bias in GPT Models**

---

## ğŸ“Œ Overview

Language models like GPT-2 have demonstrated powerful capabilities in text generation, but they often replicate and reinforce societal biases present in the data they are trained on. This project investigates the presence of **gender bias** in GPT-2 and implements methods to **reduce such bias** through counterfactual data augmentation and fine-tuning.

---

## ğŸ› ï¸ Technologies Used

- Python ğŸ
- Google Colab ğŸ““
- HuggingFace Transformers ğŸ¤—
- PyTorch ğŸ”¥
- Pandas, Matplotlib, Seaborn ğŸ“Š
- Git & GitHub ğŸ§‘â€ğŸ’»

---

## ğŸ§ª Module Implementation Steps

1. **Prompt Construction**  
   Developed a set of carefully crafted prompts reflecting different genders in varied contexts (e.g., occupations, personality traits, achievements).

2. **Synthetic Dataset Generation**  
   Generated counterfactual prompt pairs by interchanging gender terms (e.g., "He is a CEO" â†” "She is a CEO").

3. **Bias Detection & Evaluation**  
   Evaluated GPT-2's responses using lexical analysis and comparative generation.

4. **Counterfactual Data Augmentation**  
   Augmented the dataset to ensure balanced exposure of both gender perspectives.

5. **Fine-tuning GPT-2**  
   Fine-tuned the original GPT-2 model on the augmented dataset to mitigate gender bias.

6. **Post-Mitigation Evaluation**  
   Compared outputs from original and fine-tuned models to validate reduction in bias.

---

## ğŸ“ˆ Evaluation Metrics

The following were used to analyze bias and its reduction:

- **Sentiment Distribution Comparison**
- **Token-Level Lexical Differences**
- **Prompt-Based Output Divergence**
- **Visualizations (Bar Charts, Histograms, Word Clouds)**

---

## ğŸ“‚ Repository Structure

```bash
ğŸ“ Gender_Bias_Mitigation/
â”œâ”€â”€ gender_bias_dataset.csv         # Dataset of gendered prompts
â”œâ”€â”€ debiased_gpt2_model_final/     # Fine-tuned GPT-2 model folder
â”œâ”€â”€ Gender_Bias_Mitigation.ipynb   # Colab notebook with full implementation
â”œâ”€â”€ evaluation_charts/             # Optional: charts and graphs for analysis
â””â”€â”€ README.md                      # This file
